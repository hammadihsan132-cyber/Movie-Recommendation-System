# -*- coding: utf-8 -*-
"""MRS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ini3ULYl0wMqq3qFLgI0dqfdW1LEhrXj
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# Load files (adjust paths if needed)
movies  = pd.read_csv('/content/movies.csv')
tags    = pd.read_csv('/content/tags.csv')
links   = pd.read_csv('/content/links.csv')

print(movies.shape)   # ~9,700 movies in ml-latest-small
print(tags.shape)     # usually few thousand tags

movies.head()

tags.head()

links.head()

movies.info()

tags.info()

links.info()

movies.describe()

tags.describe()

links.describe()



"""# New section"""

# Clean & lowercase tags, remove very short ones if you want
tags['tag'] = tags['tag'].astype(str).str.lower().str.strip()

# Group: one row per movie → all tags concatenated
tags_agg = (
    tags.groupby('movieId')['tag']
    .apply(lambda x: ' '.join(x))
    .reset_index(name='all_tags')
)

# Optional: count how many unique tags per movie
tags_agg['tag_count'] = tags.groupby('movieId')['tag'].nunique().values

print(tags_agg.head())

"""##Create a rich text field for each movie
Combine: title + genres (cleaned) + aggregated tags
"""

# Prepare movies
movies_prep = movies.copy()

# Split genres into space-separated words
movies_prep['genres_clean'] = movies_prep['genres'].str.lower().str.replace('|', ' ')

# Clean title a bit (remove year if you want – many people keep it)
def clean_title(title):
    # Optional: remove year like (1994)
    title = re.sub(r'\s*\(\d{4}\)', '', title)
    return title.lower().strip()

movies_prep['title_clean'] = movies_prep['title'].apply(clean_title)

# Merge aggregated tags (left join → movies without tags get empty string)
movies_enriched = movies_prep.merge(tags_agg, on='movieId', how='left')
movies_enriched['all_tags'] = movies_enriched['all_tags'].fillna('')

# Final content column (the most important decision)
movies_enriched['content'] = (
    movies_enriched['title_clean'] + ' ' +
    movies_enriched['genres_clean'] + ' ' +
    movies_enriched['all_tags']
)

# Optional boost: repeat genres or title if you think they are more important
# movies_enriched['content'] = movies_enriched['genres_clean'] * 2 + ' ' + movies_enriched['content']

print(movies_enriched[['movieId', 'title', 'content']].head(8))

"""## Create TF-IDF vectors (classic & strong baseline)"""

# TF-IDF (very good starting point)
tfidf = TfidfVectorizer(
    stop_words='english',
    max_features=5000,          # prevent too high dimensionality
    ngram_range=(1, 2),         # bigrams help (sci_fi, coming_of_age)
    min_df=3                    # ignore very rare words
)

tfidf_matrix = tfidf.fit_transform(movies_enriched['content'])

print("TF-IDF shape:", tfidf_matrix.shape)  # (n_movies, n_features)

"""##Compute similarity matrix (or do it on-the-fly)
For small dataset (~9k movies) it's fine to precompute:
"""

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
# Shape: (n_movies, n_movies)

np.save('cosine_sim.npy', cosine_sim)  # save for later if you want

"""## Build the recommendation function"""

# Create reverse map: title → index
movies_enriched = movies_enriched.reset_index()
indices = pd.Series(movies_enriched.index, index=movies_enriched['title'])

def get_recommendations(title, cosine_sim=cosine_sim, top_k=10):
    if title not in indices:
        return "Movie not found."

    idx = indices[title]

    # Get pairwise sim scores for this movie
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort by similarity (descending), skip self (score=1)
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_k+1]

    # Get movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return DataFrame with title, genres, similarity
    result = movies_enriched.iloc[movie_indices][['title', 'genres']]
    result['similarity'] = [round(s[1], 4) for s in sim_scores]

    return result

# Example usage
print(get_recommendations("Matrix, The (1999)"))

print(get_recommendations("Inception (2010)"))

"""##Add posters using links.csv + TMDB (nice portfolio feature)"""

# Example: get tmdbId
def get_poster_url(movie_title):
    if movie_title not in indices:
        return None
    idx = indices[movie_title]
    movie_id = movies_enriched.loc[idx, 'movieId']
    tmdb_id = links[links['movieId'] == movie_id]['tmdbId'].values
    if len(tmdb_id) == 0 or pd.isna(tmdb_id[0]):
        return None
    tmdb_id = int(tmdb_id[0])
    # Use small poster size
    return f"https://image.tmdb.org/t/p/w185/{get_poster_path_from_tmdb_api(tmdb_id)}"
    # ^ you need TMDB API key → requests.get(...)

# Run this in your notebook (after you have trained everything)

import pickle

# Save the dataframes & models
pickle.dump(movies_enriched[['movieId','title','genres']], open('movies.pkl','wb'))
pickle.dump(tfidf_matrix, open('tfidf_matrix.pkl','wb'))           # or save sparse if memory tight
pickle.dump(cosine_sim, open('similarity.pkl','wb'))               # this is ~9742×9742 → ~350–400 MB
pickle.dump(indices.to_dict(), open('indices_dict.pkl','wb'))      # title → index mapping

# Optional: smaller version if cosine_sim is too big → save only tfidf_matrix and compute similarity on the fly

